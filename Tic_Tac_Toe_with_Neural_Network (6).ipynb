{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This project will show how adaptable neural networks can be, we will now attemp to use a neural network to learn the optimal move for Tic-Tac-Toe. We will approach this knowing that Tic-Tac-Toe is a deterministic game and that the optimal moves are already known.\n",
        "\n",
        "To train our model, we will use a list of board positions followed by the optimal response for a number of different boards. We can reduce the amount of boards to train on by considering only board position that are differnt with regard to symmetry. The non-identity transformations of a Tic-Tac-Toe board are a rotation (in either direction ) of 90 degress, 180 degrees and 270 degress a horizontal reflection and a vertical reflection. Given this idea, we will use a shortlist of boards with optimal move, apply 2 random transformations, and then feed that into our neural network for learning. \n",
        "\n",
        "Since Tic-Tac-Toe is a deterministic game, it is worth noting that whoever goes first should either win or draw. We will hope a model that can respond to our moves optimally and ultimately result in a raw.\n",
        "\n",
        "To check how our model is performing, we will do 2 things. The first check we will perform is to remove a position and an optimal move row from our training set. This will allow us to see if the neural network can generalize a move it has not seen before. The second way to evaluate our model is to actually play a game agasint it at the end"
      ],
      "metadata": {
        "id": "EdRvTbCmKKMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/lahoangquy/Tic-tac-toe-with-Neural-Network-YouTube"
      ],
      "metadata": {
        "id": "7QpO7W72M7N_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRoKOxi9JcBq",
        "outputId": "aec6f5f7-5e82-4a06-fe79-d61027af47d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g6F8-8CMT_f",
        "outputId": "fbd72d1f-f52e-4d7b-dcf7-7aa7c3928334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "#import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "9-e058kXtFOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a board\n",
        "def print_board(board):\n",
        "    symbols = ['O', ' ', 'X']\n",
        "    board_plus1 = [int(x) + 1 for x in board]\n",
        "    board_line1 = ' {} | {} | {}'.format(symbols[board_plus1[0]],\n",
        "                                         symbols[board_plus1[1]],\n",
        "                                         symbols[board_plus1[2]])\n",
        "    board_line2 = ' {} | {} | {}'.format(symbols[board_plus1[3]],\n",
        "                                         symbols[board_plus1[4]],\n",
        "                                         symbols[board_plus1[5]])\n",
        "    board_line3 = ' {} | {} | {}'.format(symbols[board_plus1[6]],\n",
        "                                         symbols[board_plus1[7]],\n",
        "                                         symbols[board_plus1[8]])\n",
        "    print(board_line1)\n",
        "    print('___________')\n",
        "    print(board_line2)\n",
        "    print('___________')\n",
        "    print(board_line3)\n",
        "# Data Augmentation\n",
        "symmetry = ['rotate180', 'rotate90', 'rotate270', 'flip_v', 'flip_h']\n",
        "\n",
        "# Given a board, a response, and a transformation, get the new board+response\n",
        "def get_symmetry(board, play_response, transformation):\n",
        "    \"\"\"\n",
        "    :param board: list of integers 9 long:\n",
        "     opposing mark = -1\n",
        "     friendly mark = 1\n",
        "     empty space = 0\n",
        "    :param play_response: integer of where response is (0-8)\n",
        "    :param transformation: one of five transformations on a board:\n",
        "     'rotate180', 'rotate90', 'rotate270', 'flip_v', 'flip_h'\n",
        "    :return: tuple: (new_board, new_response)\n",
        "    \"\"\"\n",
        "    if transformation == 'rotate180':\n",
        "        new_response = 8 - play_response\n",
        "        return board[::-1], new_response\n",
        "    elif transformation == 'rotate90':\n",
        "        new_response = [6, 3, 0, 7, 4, 1, 8, 5, 2].index(play_response)\n",
        "        tuple_board = list(zip(*[board[6:9], board[3:6], board[0:3]]))\n",
        "        return [value for item in tuple_board for value in item], new_response\n",
        "    elif transformation == 'rotate270':\n",
        "        new_response = [2, 5, 8, 1, 4, 7, 0, 3, 6].index(play_response)\n",
        "        tuple_board = list(zip(*[board[0:3], board[3:6], board[6:9]]))[::-1]\n",
        "        return [value for item in tuple_board for value in item], new_response\n",
        "    elif transformation == 'flip_v':\n",
        "        new_response = [6, 7, 8, 3, 4, 5, 0, 1, 2].index(play_response)\n",
        "        return board[6:9] + board[3:6] + board[0:3], new_response\n",
        "    elif transformation == 'flip_h':  # flip_h = rotate180, then flip_v\n",
        "        new_response = [2, 1, 0, 5, 4, 3, 8, 7, 6].index(play_response)\n",
        "        new_board = board[::-1]\n",
        "        return new_board[6:9] + new_board[3:6] + new_board[0:3], new_response\n",
        "    else:\n",
        "        raise ValueError('Method not implemented.')\n",
        "\n",
        "\n",
        "# Read in board move csv file\n",
        "def get_moves_from_csv(csv_file):\n",
        "    \"\"\"\n",
        "    :param csv_file: csv file location containing the boards w/ responses\n",
        "    :return: moves: list of moves with index of best response\n",
        "    \"\"\"\n",
        "    play_moves = []\n",
        "    with open(csv_file, 'rt') as csvfile:\n",
        "        reader = csv.reader(csvfile, delimiter=',')\n",
        "        for row in reader:\n",
        "            play_moves.append(([int(x) for x in row[0:9]], int(row[9])))\n",
        "    return play_moves\n",
        "\n",
        "\n",
        "# Get random board with optimal move\n",
        "def get_rand_move(play_moves, rand_transforms=2):\n",
        "    \"\"\"\n",
        "    :param play_moves: list of the boards w/responses\n",
        "    :param rand_transforms: how many random transforms performed on each\n",
        "    :return: (board, response), board is a list of 9 integers, response is 1 int\n",
        "    \"\"\"\n",
        "    (board, play_response) = random.choice(play_moves)\n",
        "    possible_transforms = ['rotate90', 'rotate180', 'rotate270', 'flip_v', 'flip_h']\n",
        "    for _ in range(rand_transforms):\n",
        "        random_transform = random.choice(possible_transforms)\n",
        "        (board, play_response) = get_symmetry(board, play_response, random_transform)\n",
        "    return board, play_response\n",
        "\n",
        "# Get list of optimal moves w/ responses\n",
        "moves = get_moves_from_csv('base_tic_tac_toe_moves.csv')\n",
        "# Create a train set:\n",
        "train_length = 500\n",
        "train_set = []\n",
        "for t in range(train_length):\n",
        "    train_set.append(get_rand_move(moves))\n",
        "\n",
        "# To see if the network learns anything new, we will remove\n",
        "# all instances of the board [-1, 0, 0, 1, -1, -1, 0, 0, 1],\n",
        "# which the optimal response will be the index '6'.  We will\n",
        "# Test this at the end.\n",
        "test_board = [-1, 0, 0, 1, -1, -1, 0, 0, 1]\n",
        "train_set = [x for x in train_set if x[0] != test_board]\n",
        "\n",
        "def init_weights(shape):\n",
        "    return tf.Variable(tf.random.normal(shape))\n",
        "\n",
        "A1 = init_weights([9, 81])\n",
        "bias1 = init_weights([81])\n",
        "A2 = init_weights([81, 9])\n",
        "bias2 = init_weights([9])\n",
        "\n",
        "# Initialize input data\n",
        "X = tf.keras.Input(dtype=tf.float32, batch_input_shape=[None, 9])\n",
        "hidden_output = tf.keras.layers.Lambda(lambda x: tf.nn.sigmoid(tf.add(tf.matmul(x, A1), bias1)))(X)\n",
        "# Note: we don't take the softmax at the end because our cost function does that for us\n",
        "final_output = tf.keras.layers.Lambda(lambda x: tf.add(tf.matmul(x, A2), bias2))(hidden_output)\n",
        "model = tf.keras.Model(inputs=X, outputs=final_output, name=\"tic_tac_toe_neural_network\")\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(0.025)\n",
        "\n",
        "loss_vec = []\n",
        "for i in range(10000):\n",
        "    rand_indices = np.random.choice(range(len(train_set)), batch_size, replace=False)\n",
        "    batch_data = [train_set[i] for i in rand_indices]\n",
        "    x_input = [x[0] for x in batch_data]\n",
        "    y_target = np.array([y[1] for y in batch_data])\n",
        "\n",
        "    # Open a GradientTape.\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "\n",
        "        # Forward pass.\n",
        "        output = model(np.array(x_input, dtype=float))\n",
        "\n",
        "        # Apply loss function (Cross Entropy loss)\n",
        "        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=y_target))\n",
        "        loss_vec.append(loss)\n",
        "\n",
        "    # Get gradients of loss with reference to the weights and bias variables to adjust.\n",
        "    gradients_A1 = tape.gradient(loss, A1)\n",
        "    gradients_b1 = tape.gradient(loss, bias1)\n",
        "    gradients_A2 = tape.gradient(loss, A2)\n",
        "    gradients_b2 = tape.gradient(loss, bias2)\n",
        "\n",
        "    # Update the weights and bias variables of the model.\n",
        "    optimizer.apply_gradients(zip([gradients_A1, gradients_b1, gradients_A2, gradients_b2],\n",
        "                                  [A1, bias1, A2, bias2]))\n",
        "\n",
        "    if i % 500 == 0:\n",
        "        print('Iteration: {}, Loss: {}'.format(i, loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr3zBy7etNyZ",
        "outputId": "4b10b55a-5307-4446-c96a-ecb6c434d625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (lambda_2), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'Variable:0' shape=(9, 81) dtype=float32>\n",
            "  <tf.Variable 'Variable:0' shape=(81,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (lambda_3), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'Variable:0' shape=(81, 9) dtype=float32>\n",
            "  <tf.Variable 'Variable:0' shape=(9,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0, Loss: 6.431041240692139\n",
            "Iteration: 500, Loss: 2.016533851623535\n",
            "Iteration: 1000, Loss: 1.6385409832000732\n",
            "Iteration: 1500, Loss: 1.755265712738037\n",
            "Iteration: 2000, Loss: 1.5266941785812378\n",
            "Iteration: 2500, Loss: 1.619760274887085\n",
            "Iteration: 3000, Loss: 1.5771849155426025\n",
            "Iteration: 3500, Loss: 1.320859670639038\n",
            "Iteration: 4000, Loss: 1.182477593421936\n",
            "Iteration: 4500, Loss: 1.0673573017120361\n",
            "Iteration: 5000, Loss: 1.1314177513122559\n",
            "Iteration: 5500, Loss: 1.1016783714294434\n",
            "Iteration: 6000, Loss: 1.2095882892608643\n",
            "Iteration: 6500, Loss: 0.9774430990219116\n",
            "Iteration: 7000, Loss: 1.1682740449905396\n",
            "Iteration: 7500, Loss: 1.0042903423309326\n",
            "Iteration: 8000, Loss: 0.9091327786445618\n",
            "Iteration: 8500, Loss: 0.9796607494354248\n",
            "Iteration: 9000, Loss: 1.018488883972168\n",
            "Iteration: 9500, Loss: 0.9101143479347229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss_vec, 'k-', label='Loss')\n",
        "plt.title('Loss (MSE) per Generation')\n",
        "plt.xlabel('Generation')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "BhxLo3zQt73B",
        "outputId": "2054e470-e3c1-441d-c045-1c22018daa5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above plot, we did plot the loss over the training steps.\n",
        "To test the model, we do need to see how it performs on the test board that we removed from the training set. We are hoping that the model can generalize and predict the optimal index for moving, which will be index number 6 and most of the model will succeed."
      ],
      "metadata": {
        "id": "Qncvc-lkt2et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Prediction:\n",
        "test_boards = [test_board]\n",
        "logits = model.predict(test_boards)\n",
        "predictions = tf.argmax(logits, 1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOEyIJWLtS75",
        "outputId": "dc73a598-8f4e-451f-dc07-86f3a8f18d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([6], shape=(1,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate our mpodel, we do need to play against our trained model. To do this we need to create a function that will check for a win. Thous way, our program will know when to stop asking for more moves."
      ],
      "metadata": {
        "id": "RVx4tsRVuMDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare function to check for win\n",
        "def check(board):\n",
        "    wins = [[0, 1, 2], [3, 4, 5], [6, 7, 8], [0, 3, 6], [1, 4, 7], [2, 5, 8], [0, 4, 8], [2, 4, 6]]\n",
        "    for ix in range(len(wins)):\n",
        "        if board[wins[ix][0]] == board[wins[ix][1]] == board[wins[ix][2]] == 1.:\n",
        "            return 1\n",
        "        elif board[wins[ix][0]] == board[wins[ix][1]] == board[wins[ix][2]] == -1.:\n",
        "            return -1\n",
        "    return 0"
      ],
      "metadata": {
        "id": "DbwldKACuYmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can loop through and play a game with out model. We can start with a blank board (all zeros). We will ask the user to input an index (0-8) of where to play and we can feed taht into the model for a prediction. For the model's move, we can take the largest available  prediction that is also an open space."
      ],
      "metadata": {
        "id": "Hf1BRHJ5vBxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "game_tracker = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
        "win_logical = False\n",
        "num_moves = 0\n",
        "while not win_logical:\n",
        "    player_index = input('Input index of your move (0-8): ')\n",
        "    num_moves += 1\n",
        "    # Add player move to game\n",
        "    game_tracker[int(player_index)] = 1.\n",
        "    \n",
        "    # Get model's move by first getting all the logits for each index\n",
        "    [potential_moves] = model(np.array([game_tracker], dtype=float))\n",
        "    # Now find allowed moves (where game tracker values = 0.0)\n",
        "    allowed_moves = [ix for ix, x in enumerate(game_tracker) if x == 0.0]\n",
        "    # Find best move by taking argmax of logits if they are in allowed moves\n",
        "    model_move = np.argmax([x if ix in allowed_moves else -999.0 for ix, x in enumerate(potential_moves)])\n",
        "    \n",
        "    # Add model move to game\n",
        "    game_tracker[int(model_move)] = -1.\n",
        "    print('Model has moved')\n",
        "    print_board(game_tracker)\n",
        "    # Now check for win or too many moves\n",
        "    if check(game_tracker) == -1 or num_moves >= 5:\n",
        "        print('Game Over!')\n",
        "        win_logical = True\n",
        "    elif check(game_tracker) == 1:\n",
        "        print('Congratulations, You won!')\n",
        "        win_logical = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnXID73XvAkZ",
        "outputId": "21417062-73c0-4ef8-f78f-c71d2c4c8ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input index of your move (0-8): 1\n",
            "Model has moved\n",
            " O | X |  \n",
            "___________\n",
            "   |   |  \n",
            "___________\n",
            "   |   |  \n",
            "Input index of your move (0-8): 3\n",
            "Model has moved\n",
            " O | X |  \n",
            "___________\n",
            " X |   |  \n",
            "___________\n",
            "   |   | O\n",
            "Input index of your move (0-8): 6\n",
            "Model has moved\n",
            " O | X | O\n",
            "___________\n",
            " X |   |  \n",
            "___________\n",
            " X |   | O\n",
            "Input index of your move (0-8): 7\n",
            "Model has moved\n",
            " O | X | O\n",
            "___________\n",
            " X | O |  \n",
            "___________\n",
            " X | X | O\n",
            "Game Over!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen from the above result, Our model is not perfect and we can  beat the model easily"
      ],
      "metadata": {
        "id": "Ixqmfa1LxhS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We did train a neural network to play Tic-Tac-Toe by feeding in board positions and a 9-dimensional vector and predicted the optimal response. We only had to feed in a few possible Tic-Tac-Toe boards and apply random trnasformations to each board to increase the training set size.\n",
        "\n",
        "To test our algorithm we dod remove all instances of 1 specific board and saw whether our model could generalize to predict the optimal response. Finally we did play a same game against our model. This model is not perfect yet. using more data or applying a more complex neural network architecture could be done to improve it. But the better thing we can do is to change the algorithm to reinforcement learning."
      ],
      "metadata": {
        "id": "Pgf-zfU5xqHE"
      }
    }
  ]
}