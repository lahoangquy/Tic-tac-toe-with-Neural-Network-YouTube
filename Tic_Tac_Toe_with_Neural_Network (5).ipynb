{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This project will show how adaptable neural networks can be, we will now attemp to use a neural network to learn the optimal move for Tic-Tac-Toe. We will approach this knowing that Tic-Tac-Toe is a deterministic game and that the optimal moves are already known.\n",
        "\n",
        "To train our model, we will use a list of board positions followed by the optimal response for a number of different boards. We can reduce the amount of boards to train on by considering only board position that are differnt with regard to symmetry. The non-identity transformations of a Tic-Tac-Toe board are a rotation (in either direction ) of 90 degress, 180 degrees and 270 degress a horizontal reflection and a vertical reflection. Given this idea, we will use a shortlist of boards with optimal move, apply 2 random transformations, and then feed that into our neural network for learning. \n",
        "\n",
        "Since Tic-Tac-Toe is a deterministic game, it is worth noting that whoever goes first should either win or draw. We will hope a model that can respond to our moves optimally and ultimately result in a raw.\n",
        "\n",
        "To check how our model is performing, we will do 2 things. The first check we will perform is to remove a position and an optimal move row from our training set. This will allow us to see if the neural network can generalize a move it has not seen before. The second way to evaluate our model is to actually play a game agasint it at the end"
      ],
      "metadata": {
        "id": "EdRvTbCmKKMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/lahoangquy/Tic-tac-toe-with-Neural-Network-YouTube"
      ],
      "metadata": {
        "id": "7QpO7W72M7N_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRoKOxi9JcBq",
        "outputId": "aec6f5f7-5e82-4a06-fe79-d61027af47d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g6F8-8CMT_f",
        "outputId": "fbd72d1f-f52e-4d7b-dcf7-7aa7c3928334"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "#import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "140TT5isMstn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition of X's, O's, and empty spots:\n",
        "# X = 1\n",
        "# O = -1\n",
        "# empty = 0\n",
        "# response on 1-9 grid for placement of next '1'\n",
        "\n",
        "# For example, the 'test_board' is:\n",
        "#\n",
        "#   O  |  -  |  -\n",
        "# -----------------\n",
        "#   X  |  O  |  O\n",
        "# -----------------\n",
        "#   -  |  -  |  X\n",
        "#\n",
        "# board above = [-1, 0, 0, 1, -1, -1, 0, 0, 1]\n",
        "# Optimal response would be position 6, where\n",
        "# the position numbers are:\n",
        "#\n",
        "#   0  |  1  |  2\n",
        "# -----------------\n",
        "#   3  |  4  |  5\n",
        "# -----------------\n",
        "#   6  |  7  |  8\n",
        "\n",
        "\n",
        "# Test board optimal response:\n",
        "#response = 6\n",
        "# Set batch size and five different symmetries of board positions"
      ],
      "metadata": {
        "id": "TmFsjpqGMvKl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n"
      ],
      "metadata": {
        "id": "fqC61TNTNZ59"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make visualizng the boards a bit easier, we will need to create a function taht outputs Tic-Tac-Toe boards with Xs and Os"
      ],
      "metadata": {
        "id": "6Kq0lV47NhzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a board\n",
        "def print_board(board):\n",
        "    symbols = ['O', ' ', 'X']\n",
        "    board_plus1 = [int(x) + 1 for x in board]\n",
        "    board_line1 = ' {} | {} | {}'.format(symbols[board_plus1[0]],\n",
        "                                         symbols[board_plus1[1]],\n",
        "                                         symbols[board_plus1[2]])\n",
        "    board_line2 = ' {} | {} | {}'.format(symbols[board_plus1[3]],\n",
        "                                         symbols[board_plus1[4]],\n",
        "                                         symbols[board_plus1[5]])\n",
        "    board_line3 = ' {} | {} | {}'.format(symbols[board_plus1[6]],\n",
        "                                         symbols[board_plus1[7]],\n",
        "                                         symbols[board_plus1[8]])\n",
        "    print(board_line1)\n",
        "    print('___________')\n",
        "    print(board_line2)\n",
        "    print('___________')\n",
        "    print(board_line3)"
      ],
      "metadata": {
        "id": "TisBsyTMNqO9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will need to create a function that will return a new board and an optimal response position under a transformation"
      ],
      "metadata": {
        "id": "hO6UamtcdsCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "symmetry = ['rotate180', 'rotate90', 'rotate270', 'flip_v', 'flip_h']\n",
        "\n",
        "# Given a board, a response, and a transformation, get the new board+response\n",
        "def get_symmetry(board, play_response, transformation):\n",
        "    \"\"\"\n",
        "    :param board: list of integers 9 long:\n",
        "     opposing mark = -1\n",
        "     friendly mark = 1\n",
        "     empty space = 0\n",
        "    :param play_response: integer of where response is (0-8)\n",
        "    :param transformation: one of five transformations on a board:\n",
        "     'rotate180', 'rotate90', 'rotate270', 'flip_v', 'flip_h'\n",
        "    :return: tuple: (new_board, new_response)\n",
        "    \"\"\"\n",
        "    if transformation == 'rotate180':\n",
        "        new_response = 8 - play_response\n",
        "        return board[::-1], new_response\n",
        "    elif transformation == 'rotate90':\n",
        "        new_response = [6, 3, 0, 7, 4, 1, 8, 5, 2].index(play_response)\n",
        "        tuple_board = list(zip(*[board[6:9], board[3:6], board[0:3]]))\n",
        "        return [value for item in tuple_board for value in item], new_response\n",
        "    elif transformation == 'rotate270':\n",
        "        new_response = [2, 5, 8, 1, 4, 7, 0, 3, 6].index(play_response)\n",
        "        tuple_board = list(zip(*[board[0:3], board[3:6], board[6:9]]))[::-1]\n",
        "        return [value for item in tuple_board for value in item], new_response\n",
        "    elif transformation == 'flip_v':\n",
        "        new_response = [6, 7, 8, 3, 4, 5, 0, 1, 2].index(play_response)\n",
        "        return board[6:9] + board[3:6] + board[0:3], new_response\n",
        "    elif transformation == 'flip_h':  # flip_h = rotate180, then flip_v\n",
        "        new_response = [2, 1, 0, 5, 4, 3, 8, 7, 6].index(play_response)\n",
        "        new_board = board[::-1]\n",
        "        return new_board[6:9] + new_board[3:6] + new_board[0:3], new_response\n",
        "    else:\n",
        "        raise ValueError('Method not implemented.')"
      ],
      "metadata": {
        "id": "4jMQTpAkdy8m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a function that will load the file with the boards and responses and will store it as a list of tuples"
      ],
      "metadata": {
        "id": "vT9Y8KFug2EX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_moves_from_csv(csv_file):\n",
        "    \"\"\"\n",
        "    :param csv_file: csv file location containing the boards w/ responses\n",
        "    :return: moves: list of moves with index of best response\n",
        "    \"\"\"\n",
        "    play_moves = []\n",
        "    with open(csv_file, 'rt') as csvfile:\n",
        "        reader = csv.reader(csvfile, delimiter=',')\n",
        "        for row in reader:\n",
        "            play_moves.append(([int(x) for x in row[0:9]], int(row[9])))\n",
        "    return play_moves"
      ],
      "metadata": {
        "id": "S_R_kOdugCLh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we do need to tie everything together to create a function that will return a randomly transformed board and response"
      ],
      "metadata": {
        "id": "uxECkhaPhzC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rand_move(play_moves, rand_transforms=2):\n",
        "    \"\"\"\n",
        "    :param play_moves: list of the boards w/responses\n",
        "    :param rand_transforms: how many random transforms performed on each\n",
        "    :return: (board, response), board is a list of 9 integers, response is 1 int\n",
        "    \"\"\"\n",
        "    (board, play_response) = random.choice(play_moves)\n",
        "    possible_transforms = ['rotate90', 'rotate180', 'rotate270', 'flip_v', 'flip_h']\n",
        "    for _ in range(rand_transforms):\n",
        "        random_transform = random.choice(possible_transforms)\n",
        "        (board, play_response) = get_symmetry(board, play_response, random_transform)\n",
        "    return board, play_response"
      ],
      "metadata": {
        "id": "R-IA2smuhwdm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will load our data and create a training set"
      ],
      "metadata": {
        "id": "4BMGQEPti7nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "moves = get_moves_from_csv('base_tic_tac_toe_moves.csv')\n",
        "# Create a train set:\n",
        "train_length = 500\n",
        "train_set = []\n",
        "for t in range(train_length):\n",
        "    train_set.append(get_rand_move(moves))"
      ],
      "metadata": {
        "id": "JzCT6d1ci7Ue"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rememer that we want to remove one board and an optimal response from our training set to see if the model can generalize making the best move."
      ],
      "metadata": {
        "id": "ujd9Da9ojYkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To see if the network learns anything new, we will remove\n",
        "# all instances of the board [-1, 0, 0, 1, -1, -1, 0, 0, 1],\n",
        "# which the optimal response will be the index '6'.  We will\n",
        "# Test this at the end.\n",
        "test_board = [-1, 0, 0, 1, -1, -1, 0, 0, 1]\n",
        "train_set = [x for x in train_set if x[0] != test_board]"
      ],
      "metadata": {
        "id": "Rsz6C0MXjXoU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We do need to initialize the weights and bias and create our models\n",
        "def init_weights(shape):\n",
        "    return tf.Variable(tf.random.normal(shape))\n",
        "A1 = init_weights([9, 81])\n",
        "bias1 = init_weights([81])\n",
        "A2 = init_weights([81, 9])\n",
        "bias2 = init_weights([9])"
      ],
      "metadata": {
        "id": "V68yfZTdj-KU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create our mode. Note that we do not include the softmax() activation function because it is included in the lost function"
      ],
      "metadata": {
        "id": "q3NlTAjQkemQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize input data\n",
        "X = tf.keras.Input(dtype=tf.float32, batch_input_shape=[None, 9])\n",
        "hidden_output = tf.keras.layers.Lambda(lambda x: tf.nn.sigmoid(tf.add(tf.matmul(x, A1), bias1)))(X)\n",
        "# Note: we don't take the softmax at the end because our cost function does that for us\n",
        "final_output = tf.keras.layers.Lambda(lambda x: tf.add(tf.matmul(x, A2), bias2))(hidden_output)\n",
        "model = tf.keras.Model(inputs=X, outputs=final_output, name=\"tic tac toe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKTFd0Tmkdeh",
        "outputId": "2d3e9a16-52ce-4a71-94d9-791c912d40ed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (lambda), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'Variable:0' shape=(9, 81) dtype=float32>\n",
            "  <tf.Variable 'Variable:0' shape=(81,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (lambda_1), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'Variable:0' shape=(81, 9) dtype=float32>\n",
            "  <tf.Variable 'Variable:0' shape=(9,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will declare our optimizer\n",
        "optimizer = tf.keras.optimizers.SGD(0.025)"
      ],
      "metadata": {
        "id": "QSThHF7vloVC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now loop through the training of our neural network. Note that our loss function will be the average softmax of the final output logits"
      ],
      "metadata": {
        "id": "F-vUn_QjlxCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_vec = []\n",
        "for i in range(10000):\n",
        "    rand_indices = np.random.choice(range(len(train_set)), batch_size, replace=False)\n",
        "    batch_data = [train_set[i] for i in rand_indices]\n",
        "    x_input = [x[0] for x in batch_data]\n",
        "    y_target = np.array([y[1] for y in batch_data])\n",
        "\n",
        "    # Open a GradientTape.\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "\n",
        "        # Forward pass.\n",
        "        output = model(np.array(x_input, dtype=float))\n",
        "\n",
        "        # Apply loss function (Cross Entropy loss)\n",
        "        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=y_target))\n",
        "        loss_vec.append(loss)\n",
        "\n",
        "    # Get gradients of loss with reference to the weights and bias variables to adjust.\n",
        "    gradients_A1 = tape.gradient(loss, A1)\n",
        "    gradients_b1 = tape.gradient(loss, bias1)\n",
        "    gradients_A2 = tape.gradient(loss, A2)\n",
        "    gradients_b2 = tape.gradient(loss, bias2)\n",
        "\n",
        "    # Update the weights and bias variables of the model.\n",
        "    optimizer.apply_gradients(zip([gradients_A1, gradients_b1, gradients_A2, gradients_b2],\n",
        "                                  [A1, bias1, A2, bias2]))\n",
        "\n",
        "    if i % 500 == 0:\n",
        "        print('Iteration: {}, Loss: {}'.format(i, loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhvA9QBjl8eY",
        "outputId": "ebfb4418-511b-4058-8d96-cf68b5f63f5c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0, Loss: 7.945645332336426\n",
            "Iteration: 500, Loss: 1.865727424621582\n",
            "Iteration: 1000, Loss: 1.5998142957687378\n",
            "Iteration: 1500, Loss: 1.6589170694351196\n",
            "Iteration: 2000, Loss: 1.3871594667434692\n",
            "Iteration: 2500, Loss: 1.3872671127319336\n",
            "Iteration: 3000, Loss: 1.1046247482299805\n",
            "Iteration: 3500, Loss: 1.0914956331253052\n",
            "Iteration: 4000, Loss: 1.048866868019104\n",
            "Iteration: 4500, Loss: 0.8853231072425842\n",
            "Iteration: 5000, Loss: 0.9256417155265808\n",
            "Iteration: 5500, Loss: 0.9089015126228333\n",
            "Iteration: 6000, Loss: 0.9707467555999756\n",
            "Iteration: 6500, Loss: 0.81446373462677\n",
            "Iteration: 7000, Loss: 0.9326468110084534\n",
            "Iteration: 7500, Loss: 0.6198672652244568\n",
            "Iteration: 8000, Loss: 0.6715857982635498\n",
            "Iteration: 8500, Loss: 0.7007814049720764\n",
            "Iteration: 9000, Loss: 0.8517657518386841\n",
            "Iteration: 9500, Loss: 0.682719886302948\n"
          ]
        }
      ]
    }
  ]
}